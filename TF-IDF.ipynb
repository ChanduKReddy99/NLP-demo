{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd4c68c-f9d4-4f55-be12-039b54c0f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3c56ad-8134-4696-9b5d-496d6d3fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start this with a smaller data:\n",
    "\n",
    "data= 'hello everybody!. Well-come to NLP tutorial. We are going to see the simple text preprocessing. I am going \\\n",
    "to use stemmer & lemmatization from nltk library.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb411f54-f33e-406b-bb7d-9a4514bdfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents= nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66bcbb03-32d5-4fd7-bcb1-f44e61bb5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets clean the data :\n",
    "\n",
    "corpus=[]\n",
    "\n",
    "for i in range(len(sents)):\n",
    "    review= re.sub('[^a-zA-Z]',' ', sents[i])\n",
    "    review= review.lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91756139-b209-45aa-8016-5ebeb5617e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello everybody  ',\n",
       " 'well come to nlp tutorial ',\n",
       " 'we are going to see the simple text preprocessing ',\n",
       " 'i am going to use stemmer   lemmatization from nltk library ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b409fb44-643a-4436-92de-f91c8dba9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets apply TF-IDF to the above corpus\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "tf_idf_vects= tf_idf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f0c73d-63dd-4354-adc1-e9cb2b1da598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['am', 'are', 'come', 'everybody', 'from', 'going', 'hello',\n",
       "       'lemmatization', 'library', 'nlp', 'nltk', 'preprocessing', 'see',\n",
       "       'simple', 'stemmer', 'text', 'the', 'to', 'tutorial', 'use', 'we',\n",
       "       'well'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b1f139-fda4-4bf6-933b-b27ea1466413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 6,\n",
       " 'everybody': 3,\n",
       " 'well': 21,\n",
       " 'come': 2,\n",
       " 'to': 17,\n",
       " 'nlp': 9,\n",
       " 'tutorial': 18,\n",
       " 'we': 20,\n",
       " 'are': 1,\n",
       " 'going': 5,\n",
       " 'see': 12,\n",
       " 'the': 16,\n",
       " 'simple': 13,\n",
       " 'text': 15,\n",
       " 'preprocessing': 11,\n",
       " 'am': 0,\n",
       " 'use': 19,\n",
       " 'stemmer': 14,\n",
       " 'lemmatization': 7,\n",
       " 'from': 4,\n",
       " 'nltk': 10,\n",
       " 'library': 8}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f174fe6c-291a-49a0-a9ca-af711b0fdc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.70710678, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.47633035, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.47633035,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30403549, 0.47633035, 0.        ,\n",
       "        0.        , 0.47633035],\n",
       "       [0.        , 0.35291425, 0.        , 0.        , 0.        ,\n",
       "        0.27824164, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.35291425, 0.35291425, 0.35291425, 0.        ,\n",
       "        0.35291425, 0.35291425, 0.22526059, 0.        , 0.        ,\n",
       "        0.35291425, 0.        ],\n",
       "       [0.35291425, 0.        , 0.        , 0.        , 0.35291425,\n",
       "        0.27824164, 0.        , 0.35291425, 0.35291425, 0.        ,\n",
       "        0.35291425, 0.        , 0.        , 0.        , 0.35291425,\n",
       "        0.        , 0.        , 0.22526059, 0.        , 0.35291425,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the transformed vector:\n",
    "\n",
    "tf_idf_vects.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6727f54a-9d81-4207-a05f-6867dd5160f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 22)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets chekc the size fo the vector\n",
    "\n",
    "tf_idf_vects.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349ed40-c246-424f-8790-aaae71a239c6",
   "metadata": {},
   "source": [
    "Note: 4 sentences and each sentence has 22 vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2be92885-78fe-4a51-a338-af4c5c65cbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.70710678, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want the 1st sentence vector:\n",
    "\n",
    "tf_idf_vects[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66959646-ccd1-498e-ad1e-a49e5bea6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets apply TF-IDF on a larger data:\n",
    "\n",
    "paragraph =  open('C:/Users/acreddy/Desktop/spacy_ds/nlp.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d30bda-e948-4bac-9c9b-49900e5e2efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have three visions for India. In 3000 years of our history, people from all over \\nthe world have come and invaded us, captured our lands, conquered our minds. \\nFrom Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\nthe French, the Dutch, all of them came and looted us, took over what was ours. \\nYet we have not done this to any other nation. We have not conquered anyone. \\nWe have not grabbed their land, their culture, \\ntheir history and tried to enforce our way of life on them. \\nWhy? Because we respect the freedom of others.That is why my \\nfirst vision is that of freedom. I believe that India got its first vision of \\nthis in 1857, when we started the War of Independence. It is this freedom that\\nwe must protect and nurture and build on. If we are not free, no one will respect us.\\nMy second vision for Indiaâ€™s development. For fifty years we have been a developing nation.\\nIt is time we see ourselves as a developed nation. We are among the top 5 nations of the world\\nin terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\\nOur achievements are being globally recognised today. Yet we lack the self-confidence to\\nsee ourselves as a developed nation, self-reliant and self-assured. Isnâ€™t this incorrect?\\nI have a third vision. India must stand up to the world. Because I believe that unless India \\nstands up to the world, no one will respect us. Only strength respects strength. We must be \\nstrong not only as a military power but also as an economic power. Both must go hand-in-hand. \\nMy good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \\nspace, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\\nI was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \\nI see four milestones in my career.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b770f8f-7e3b-41e5-9308-dd78f6d55b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown in to sentences:\n",
    "\n",
    "sentences= nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "741056af-f4df-40e2-9e86-c75d15726787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\nthe world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\nthe French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.',\n",
       " 'We have not grabbed their land, their culture, \\ntheir history and tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.That is why my \\nfirst vision is that of freedom.',\n",
       " 'I believe that India got its first vision of \\nthis in 1857, when we started the War of Independence.',\n",
       " 'It is this freedom that\\nwe must protect and nurture and build on.',\n",
       " 'If we are not free, no one will respect us.',\n",
       " 'My second vision for Indiaâ€™s development.',\n",
       " 'For fifty years we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top 5 nations of the world\\nin terms of GDP.',\n",
       " 'We have a 10 percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling.',\n",
       " 'Our achievements are being globally recognised today.',\n",
       " 'Yet we lack the self-confidence to\\nsee ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isnâ€™t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India \\nstands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be \\nstrong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of \\nspace, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6bbcbb-fa62-4d40-a15a-b28b1e18377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data:\n",
    "\n",
    "corpus1= []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    review= re.sub('[^a-zA-Z0-9]',' ', sentences[i])\n",
    "    review= review.lower()\n",
    "    corpus1.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3ff7cf6-1fac-402d-b51e-42e577c2a54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have three visions for india ',\n",
       " 'in 3000 years of our history  people from all over  the world have come and invaded us  captured our lands  conquered our minds ',\n",
       " 'from alexander onwards  the greeks  the turks  the moguls  the portuguese  the british  the french  the dutch  all of them came and looted us  took over what was ours ',\n",
       " 'yet we have not done this to any other nation ',\n",
       " 'we have not conquered anyone ',\n",
       " 'we have not grabbed their land  their culture   their history and tried to enforce our way of life on them ',\n",
       " 'why ',\n",
       " 'because we respect the freedom of others that is why my  first vision is that of freedom ',\n",
       " 'i believe that india got its first vision of  this in 1857  when we started the war of independence ',\n",
       " 'it is this freedom that we must protect and nurture and build on ',\n",
       " 'if we are not free  no one will respect us ',\n",
       " 'my second vision for india   s development ',\n",
       " 'for fifty years we have been a developing nation ',\n",
       " 'it is time we see ourselves as a developed nation ',\n",
       " 'we are among the top 5 nations of the world in terms of gdp ',\n",
       " 'we have a 10 percent growth rate in most areas ',\n",
       " 'our poverty levels are falling ',\n",
       " 'our achievements are being globally recognised today ',\n",
       " 'yet we lack the self confidence to see ourselves as a developed nation  self reliant and self assured ',\n",
       " 'isn   t this incorrect ',\n",
       " 'i have a third vision ',\n",
       " 'india must stand up to the world ',\n",
       " 'because i believe that unless india  stands up to the world  no one will respect us ',\n",
       " 'only strength respects strength ',\n",
       " 'we must be  strong not only as a military power but also as an economic power ',\n",
       " 'both must go hand in hand ',\n",
       " 'my good fortune was to have worked with three great minds ',\n",
       " 'dr  vikram sarabhai of the dept ',\n",
       " 'of  space  professor satish dhawan  who succeeded him and dr  brahm prakash  father of nuclear material ',\n",
       " 'i was lucky to have worked with all three of them closely and consider this the great opportunity of my life ',\n",
       " 'i see four milestones in my career ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3691bfdd-e04f-4365-8fd6-07b0aaa7a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let sapply TF-IDF:\n",
    "\n",
    "tf_idf= TfidfVectorizer()\n",
    "\n",
    "tf_idf_vectors= tf_idf.fit_transform(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb22a21c-fd13-4833-96d8-5f06cddbbca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '1857', '3000', 'achievements', 'alexander', 'all', 'also',\n",
       "       'among', 'an', 'and', 'any', 'anyone', 'are', 'areas', 'as',\n",
       "       'assured', 'be', 'because', 'been', 'being', 'believe', 'both',\n",
       "       'brahm', 'british', 'build', 'but', 'came', 'captured', 'career',\n",
       "       'closely', 'come', 'confidence', 'conquered', 'consider',\n",
       "       'culture', 'dept', 'developed', 'developing', 'development',\n",
       "       'dhawan', 'done', 'dr', 'dutch', 'economic', 'enforce', 'falling',\n",
       "       'father', 'fifty', 'first', 'for', 'fortune', 'four', 'free',\n",
       "       'freedom', 'french', 'from', 'gdp', 'globally', 'go', 'good',\n",
       "       'got', 'grabbed', 'great', 'greeks', 'growth', 'hand', 'have',\n",
       "       'him', 'history', 'if', 'in', 'incorrect', 'independence', 'india',\n",
       "       'invaded', 'is', 'isn', 'it', 'its', 'lack', 'land', 'lands',\n",
       "       'levels', 'life', 'looted', 'lucky', 'material', 'milestones',\n",
       "       'military', 'minds', 'moguls', 'most', 'must', 'my', 'nation',\n",
       "       'nations', 'no', 'not', 'nuclear', 'nurture', 'of', 'on', 'one',\n",
       "       'only', 'onwards', 'opportunity', 'other', 'others', 'our', 'ours',\n",
       "       'ourselves', 'over', 'people', 'percent', 'portuguese', 'poverty',\n",
       "       'power', 'prakash', 'professor', 'protect', 'rate', 'recognised',\n",
       "       'reliant', 'respect', 'respects', 'sarabhai', 'satish', 'second',\n",
       "       'see', 'self', 'space', 'stand', 'stands', 'started', 'strength',\n",
       "       'strong', 'succeeded', 'terms', 'that', 'the', 'their', 'them',\n",
       "       'third', 'this', 'three', 'time', 'to', 'today', 'took', 'top',\n",
       "       'tried', 'turks', 'unless', 'up', 'us', 'vikram', 'vision',\n",
       "       'visions', 'war', 'was', 'way', 'we', 'what', 'when', 'who', 'why',\n",
       "       'will', 'with', 'worked', 'world', 'years', 'yet'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d585064-f023-4161-b1cc-978c5c6d6ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'have': 66,\n",
       " 'three': 144,\n",
       " 'visions': 157,\n",
       " 'for': 49,\n",
       " 'india': 73,\n",
       " 'in': 70,\n",
       " '3000': 2,\n",
       " 'years': 170,\n",
       " 'of': 100,\n",
       " 'our': 108,\n",
       " 'history': 68,\n",
       " 'people': 112,\n",
       " 'from': 55,\n",
       " 'all': 5,\n",
       " 'over': 111,\n",
       " 'the': 139,\n",
       " 'world': 169,\n",
       " 'come': 30,\n",
       " 'and': 9,\n",
       " 'invaded': 74,\n",
       " 'us': 154,\n",
       " 'captured': 27,\n",
       " 'lands': 81,\n",
       " 'conquered': 32,\n",
       " 'minds': 89,\n",
       " 'alexander': 4,\n",
       " 'onwards': 104,\n",
       " 'greeks': 63,\n",
       " 'turks': 151,\n",
       " 'moguls': 90,\n",
       " 'portuguese': 114,\n",
       " 'british': 23,\n",
       " 'french': 54,\n",
       " 'dutch': 42,\n",
       " 'them': 141,\n",
       " 'came': 26,\n",
       " 'looted': 84,\n",
       " 'took': 148,\n",
       " 'what': 162,\n",
       " 'was': 159,\n",
       " 'ours': 109,\n",
       " 'yet': 171,\n",
       " 'we': 161,\n",
       " 'not': 97,\n",
       " 'done': 40,\n",
       " 'this': 143,\n",
       " 'to': 146,\n",
       " 'any': 10,\n",
       " 'other': 106,\n",
       " 'nation': 94,\n",
       " 'anyone': 11,\n",
       " 'grabbed': 61,\n",
       " 'their': 140,\n",
       " 'land': 80,\n",
       " 'culture': 34,\n",
       " 'tried': 150,\n",
       " 'enforce': 44,\n",
       " 'way': 160,\n",
       " 'life': 83,\n",
       " 'on': 101,\n",
       " 'why': 165,\n",
       " 'because': 17,\n",
       " 'respect': 123,\n",
       " 'freedom': 53,\n",
       " 'others': 107,\n",
       " 'that': 138,\n",
       " 'is': 75,\n",
       " 'my': 93,\n",
       " 'first': 48,\n",
       " 'vision': 156,\n",
       " 'believe': 20,\n",
       " 'got': 60,\n",
       " 'its': 78,\n",
       " '1857': 1,\n",
       " 'when': 163,\n",
       " 'started': 133,\n",
       " 'war': 158,\n",
       " 'independence': 72,\n",
       " 'it': 77,\n",
       " 'must': 92,\n",
       " 'protect': 119,\n",
       " 'nurture': 99,\n",
       " 'build': 24,\n",
       " 'if': 69,\n",
       " 'are': 12,\n",
       " 'free': 52,\n",
       " 'no': 96,\n",
       " 'one': 102,\n",
       " 'will': 166,\n",
       " 'second': 127,\n",
       " 'development': 38,\n",
       " 'fifty': 47,\n",
       " 'been': 18,\n",
       " 'developing': 37,\n",
       " 'time': 145,\n",
       " 'see': 128,\n",
       " 'ourselves': 110,\n",
       " 'as': 14,\n",
       " 'developed': 36,\n",
       " 'among': 7,\n",
       " 'top': 149,\n",
       " 'nations': 95,\n",
       " 'terms': 137,\n",
       " 'gdp': 56,\n",
       " '10': 0,\n",
       " 'percent': 113,\n",
       " 'growth': 64,\n",
       " 'rate': 120,\n",
       " 'most': 91,\n",
       " 'areas': 13,\n",
       " 'poverty': 115,\n",
       " 'levels': 82,\n",
       " 'falling': 45,\n",
       " 'achievements': 3,\n",
       " 'being': 19,\n",
       " 'globally': 57,\n",
       " 'recognised': 121,\n",
       " 'today': 147,\n",
       " 'lack': 79,\n",
       " 'self': 129,\n",
       " 'confidence': 31,\n",
       " 'reliant': 122,\n",
       " 'assured': 15,\n",
       " 'isn': 76,\n",
       " 'incorrect': 71,\n",
       " 'third': 142,\n",
       " 'stand': 131,\n",
       " 'up': 153,\n",
       " 'unless': 152,\n",
       " 'stands': 132,\n",
       " 'only': 103,\n",
       " 'strength': 134,\n",
       " 'respects': 124,\n",
       " 'be': 16,\n",
       " 'strong': 135,\n",
       " 'military': 88,\n",
       " 'power': 116,\n",
       " 'but': 25,\n",
       " 'also': 6,\n",
       " 'an': 8,\n",
       " 'economic': 43,\n",
       " 'both': 21,\n",
       " 'go': 58,\n",
       " 'hand': 65,\n",
       " 'good': 59,\n",
       " 'fortune': 50,\n",
       " 'worked': 168,\n",
       " 'with': 167,\n",
       " 'great': 62,\n",
       " 'dr': 41,\n",
       " 'vikram': 155,\n",
       " 'sarabhai': 125,\n",
       " 'dept': 35,\n",
       " 'space': 130,\n",
       " 'professor': 118,\n",
       " 'satish': 126,\n",
       " 'dhawan': 39,\n",
       " 'who': 164,\n",
       " 'succeeded': 136,\n",
       " 'him': 67,\n",
       " 'brahm': 22,\n",
       " 'prakash': 117,\n",
       " 'father': 46,\n",
       " 'nuclear': 98,\n",
       " 'material': 86,\n",
       " 'lucky': 85,\n",
       " 'closely': 29,\n",
       " 'consider': 33,\n",
       " 'opportunity': 105,\n",
       " 'four': 51,\n",
       " 'milestones': 87,\n",
       " 'career': 28}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cb9c832-e0ac-4a9c-bf49-b7ffc5eb093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.22629718, ..., 0.17133386, 0.20197552,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get the transformed vectors:\n",
    "\n",
    "tf_idf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d14d0e7-b0a7-4b2f-bb9b-bd468933f669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 172)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectors.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a17b4-f336-48e2-8f62-3d4b73fb0c9d",
   "metadata": {},
   "source": [
    "Note: 31 sentences and each sentence having 172 vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ae91fea-e151-4dc5-96dc-86b7653d0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets apply ngram and max_frequency(max_features value gives the minimum those many times repeated values only. i,e. if i give max_features=2 then it prints only the words who repeated more than 2 times in corpus \n",
    "\n",
    "tf_idf= TfidfVectorizer(ngram_range=(1,2),max_features=2)\n",
    "\n",
    "tf_id_vect= tf_idf.fit_transform(corpus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1541e5dd-4576-425e-8b4a-f4c4e6ad5b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['of', 'the'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it gives only the minimum 2 times repeated words only in the corpus:\n",
    "\n",
    "tf_idf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c73f51d4-fbe9-43bb-a1e0-b5ec5b459c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'of': 0, 'the': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since it has only 2 words repeated 2 or more times:\n",
    "\n",
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da019f-3a43-47e6-92da-092bd4007d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583deb66-4d7d-447e-bc6e-77977f86696d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
